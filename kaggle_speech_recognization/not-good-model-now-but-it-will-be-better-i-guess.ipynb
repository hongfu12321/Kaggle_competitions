{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Import Utilities libary\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "from os.path import isdir, join\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "print('Finish Import Utilities libary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish import model library\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from random import randint\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import activations, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Dense, Input, Dropout, Flatten\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "print('Finish import model library')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    '''Get data from the path and create a pandas dataframe to store it,\n",
    "    the function will return a pandas dataframe with fpath(file path) and label'''\n",
    "    \n",
    "    label_list = []\n",
    "    fname = []\n",
    "    valid_label = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence']\n",
    "\n",
    "    # Get every audio files path and label\n",
    "    files = [(str(file), file.parts[-2]) for file in Path(path).glob(\"**/*.wav\") if file]\n",
    "    file_len = len(files)\n",
    "    print('Finish getting data')\n",
    "    \n",
    "    # Valid label name\n",
    "    for file in files:\n",
    "        if file[1] == '_background_noise_':\n",
    "            label = 'silence'\n",
    "        elif file[1] not in valid_label:\n",
    "            label = 'unknown'\n",
    "        else:\n",
    "            label = file[1]\n",
    "            \n",
    "        # Normal version training set, but only got 0.6 points in kaggle\n",
    "#         label_list.append(label)\n",
    "#         fname.append(file[0])\n",
    "\n",
    "        # Try to only train valid-label data\n",
    "        if label in valid_label:\n",
    "            label_list.append(label)\n",
    "            fname.append(file[0])\n",
    "        \n",
    "    data = pd.DataFrame({'fpath': fname, 'label': label_list})\n",
    "    \n",
    "    print('Finish appending array')\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish getting data\n",
      "Finish appending array\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18950 entries, 2300 to 9783\n",
      "Data columns (total 2 columns):\n",
      "fpath    18950 non-null object\n",
      "label    18950 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 444.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4738 entries, 16385 to 8189\n",
      "Data columns (total 2 columns):\n",
      "fpath    4738 non-null object\n",
      "label    4738 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 111.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4738 4738\n"
     ]
    }
   ],
   "source": [
    "# Get train data set\n",
    "train_df = get_data('./train/audio')\n",
    "\n",
    "# Seperate train set and validation set\n",
    "train_set = train_df.sample(frac=0.8, replace=False, random_state=42)\n",
    "valid_set = train_df.loc[set(train_df.index) - set(train_set.index)]\n",
    "\n",
    "y_train = np.array(train_set.label)\n",
    "y_train = pd.get_dummies(y_train, dtype=bool)\n",
    "x_train = np.array(train_set.fpath)\n",
    "\n",
    "y_valid = np.array(valid_set.label)\n",
    "y_valid = pd.get_dummies(y_valid, dtype=bool)\n",
    "x_valid = np.array(valid_set.fpath)\n",
    "\n",
    "display(train_set.info())\n",
    "display(valid_set.info())\n",
    "gc.collect()\n",
    "\n",
    "print(len(x_valid), len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(shape):\n",
    "    '''Create a keras functional model'''\n",
    "    \n",
    "    inputlayer = Input(shape=shape)\n",
    "    \n",
    "    # Nornal model\n",
    "#     nclass = 12\n",
    "    \n",
    "    # Experience model\n",
    "    nclass = 11\n",
    "    \n",
    "    norm_input = BatchNormalization()(inputlayer)\n",
    "    model = Conv2D(16, kernel_size=2, padding='same', activation=activations.relu)(norm_input)\n",
    "    model = Conv2D(16, kernel_size=2, padding='same', activation=activations.relu)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Dropout(rate=0.2)(model)\n",
    "    model = Conv2D(32, kernel_size=3, padding='same', activation=activations.relu)(model)\n",
    "    model = Conv2D(32, kernel_size=3, padding='same', activation=activations.relu)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Dropout(rate=0.2)(model)\n",
    "    model = Conv2D(64, kernel_size=3, padding='same', activation=activations.relu)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Dropout(rate=0.2)(model)\n",
    "    model = Flatten()(model) \n",
    "\n",
    "    dense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(model))\n",
    "    dense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(dense_1))\n",
    "    dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inputlayer, outputs=dense_1)\n",
    "    model.compile(optimizer='adam', loss=tf.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (99, 161, 1)\n",
    "model = get_model(shape)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "def get_spectrogram(paths, y=None, nsamples=16000):\n",
    "    wavs = [wavfile.read(path)[1] for path in paths]\n",
    "    \n",
    "    data = []\n",
    "    label = []\n",
    "    for wav in wavs:\n",
    "        try:\n",
    "            if wav.size < 16000:\n",
    "                d = np.pad(wav, (nsamples - wav.size, 0), mode='constant')\n",
    "            else:\n",
    "                d = wav[0:nsamples]\n",
    "            data.append(d)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    spg = [log_specgram(d, nsamples)[2] for d in data]\n",
    "    spg = [s.reshape(99, 161, -1) for s in spg]\n",
    "    return (spg)\n",
    "\n",
    "def batch_generator(x, y, batch_size=16):\n",
    "    # Return a random image from X, y\n",
    "    ylen = len(y)\n",
    "    loopcount = ylen // batch_size\n",
    "    while True:\n",
    "        i = randint(0,loopcount)\n",
    "        x_list = x[i * batch_size:(i + 1) * batch_size]\n",
    "        spgs = get_spectrogram(x_list)\n",
    "        \n",
    "        yield np.concatenate([spgs]), y[i * batch_size:(i + 1) * batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1812/1895 [===========================>..] - ETA: 10s - loss: 0.1864 - accuracy: 0.9328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongfu1220/.local/lib/python3.5/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1895/1895 [==============================] - 264s 139ms/step - loss: 0.1834 - accuracy: 0.9338 - val_loss: 0.1791 - val_accuracy: 0.9351\n",
      "Epoch 2/12\n",
      "1895/1895 [==============================] - 257s 136ms/step - loss: 0.0928 - accuracy: 0.9658 - val_loss: 0.0683 - val_accuracy: 0.9759\n",
      "Epoch 3/12\n",
      "1259/1895 [==================>...........] - ETA: 1:20 - loss: 0.0689 - accuracy: 0.9742"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_4 to have 4 dimensions, but got array with shape (0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3185dc76c11e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1236\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n\u001b[1;32m   1237\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m         extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2594\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2596\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2598\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    338\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_4 to have 4 dimensions, but got array with shape (0, 1)"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 10\n",
    "epochs = 12\n",
    "path = './tensorboard/keras_' + str(time())\n",
    "history = model.fit_generator(\n",
    "    generator=batch_generator(x_train, y_train, batch_size),\n",
    "    validation_data=batch_generator(x_valid, y_valid, batch_size),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=y_train.shape[0] // batch_size,\n",
    "    validation_steps=y_valid.shape[0] // batch_size,\n",
    "    callbacks=[TensorBoard(log_dir=path)],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "path = './model/model_' + str(time()) + '.h5'\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Predict the test file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model version we like\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model1 = load_model('./model/model_1553894437.5339348.h5')\n",
    "\n",
    "# Normal model\n",
    "# pred_list = [\n",
    "#     'down', 'go', 'left', 'no', 'off', 'on', 'right',\n",
    "#     'silence', 'stop', 'unknown', 'up', 'yes'\n",
    "# ]\n",
    "\n",
    "# Experient model\n",
    "pred_list = [\n",
    "    'down', 'go', 'left', 'no', 'off', 'on', 'right',\n",
    "    'silence', 'stop', 'up', 'yes'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/158538, time: 0.0002 s\r\n",
      "Finish prediction\n",
      "Saved csv file\n",
      "unknown    100\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''log_specgram() and get_spectrogram() defined before '''\n",
    "\n",
    "def get_prediction(path, model, pred_list, nsamples=16000):\n",
    "    '''Predict the test files and return a pandas dataframe with submission format'''\n",
    "    prediction = []\n",
    "    file_name = []\n",
    "    \n",
    "    # Get every files path and file's label in test directory\n",
    "    file_names = [(str(file), file.parts[-2]) for file in Path(path).glob(\"**/*.wav\") if file]\n",
    "    i, file_len = 0, len(file_names)\n",
    "    \n",
    "    start_time = time()\n",
    "    for name in file_names[0:None]:\n",
    "        try:\n",
    "            spg = get_spectrogram([name[0]])\n",
    "            pred = model.predict(np.array(spg))\n",
    "\n",
    "            # Add threshold to prediction\n",
    "            if (pred.max() > 0.5):    \n",
    "                pred = np.argmax(pred, axis=1)\n",
    "                pred = pred_list[pred[0]]\n",
    "            else:\n",
    "                pred = 'unknown'\n",
    "        except:\n",
    "            pred = 'unknown'\n",
    "        prediction.append(pred)\n",
    "        file_name.append(name[0].split('/')[-1])\n",
    "\n",
    "        # Fancy progress bar\n",
    "        i = i + 1\n",
    "        if i % 100 == 0:\n",
    "            print(\"%d/%d, time: %.4f s\" % (i, file_len, time() - start_time), end='\\r')\n",
    "    print('\\nFinish prediction')\n",
    "\n",
    "    submission = pd.DataFrame(\n",
    "        {\n",
    "            'fname': file_name,\n",
    "            'label': prediction\n",
    "        }\n",
    "    )\n",
    "    return submission\n",
    "submission = get_prediction('./test/audio/', model1, pred_list)\n",
    "submission.to_csv('submission1.csv', index=False)\n",
    "print('Saved csv file')\n",
    "print(pd.value_counts(submission.label.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
