{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "# from tensorflow.python.data import Dataset\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# read csv\n",
    "train_data = pd.read_csv(\"./dataSet/train.csv\")\n",
    "test_data = pd.read_csv(\"./dataSet/test.csv\")\n",
    "\n",
    "test_data_copy = test_data.copy()\n",
    "train_data_copy = train_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display.display(train_data.describe())\n",
    "# display.display(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_features(input_data):\n",
    "    return (set([tf.feature_column.numeric_column(my_feature)\n",
    "                 for my_feature in input_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_example, learning_rate, batch_size, steps, periods, mod_dir):\n",
    "    # Use sample method to seperate train dataset and validation dataset\n",
    "    train_set = train_example.sample(frac=0.8, replace=False, random_state=100)\n",
    "    cv_set = train_example.loc[set(train_example.index) - set(train_set.index)]\n",
    "    feature_columns = construct_features(train_example.drop('SalePrice', axis=1))\n",
    "    \n",
    "    # Create train and cv input function\n",
    "    train_input = tf.estimator.inputs.pandas_input_fn(\n",
    "        x = train_set.drop('SalePrice', axis=1),\n",
    "        y = train_set.SalePrice,\n",
    "        num_epochs=None,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    train_eval_input = tf.estimator.inputs.pandas_input_fn(\n",
    "        x = train_set.drop('SalePrice', axis=1),\n",
    "        y = train_set.SalePrice,\n",
    "        num_epochs=1,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    cv_input = tf.estimator.inputs.pandas_input_fn(\n",
    "        x = cv_set.drop('SalePrice', axis=1),\n",
    "        y = cv_set.SalePrice,\n",
    "        num_epochs=1,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    # Declare optimizer for estimator\n",
    "    my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 2.5)\n",
    "    estimator = tf.estimator.DNNRegressor(\n",
    "        hidden_units=[256, 128, 64],\n",
    "        feature_columns=feature_columns,\n",
    "        optimizer=my_optimizer,\n",
    "        model_dir=mod_dir\n",
    "    )\n",
    "    \n",
    "    training_rmse = []\n",
    "    validation_rmse = []\n",
    "    \n",
    "    for i in range (periods):\n",
    "        # Train model\n",
    "        print('%d period:' % (i + 1), end='')\n",
    "        estimator.train(input_fn=train_input, steps=steps)\n",
    "        \n",
    "        # Evaluate model with validation dataset\n",
    "        eval_cv = estimator.evaluate(input_fn=cv_input)\n",
    "        print(eval_cv['average_loss'], end=' ')\n",
    "        \n",
    "        # Take a break and compute predictions.\n",
    "        training_predictions = estimator.predict(input_fn=train_eval_input)\n",
    "        training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
    "        validation_predictions = estimator.predict(input_fn=cv_input)\n",
    "        validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
    "    \n",
    "        # Compute training and validation loss.\n",
    "        training_root_mean_squared_error = math.sqrt(\n",
    "            metrics.mean_squared_error(training_predictions, train_set.SalePrice))\n",
    "        validation_root_mean_squared_error = math.sqrt(\n",
    "            metrics.mean_squared_error(validation_predictions, cv_set.SalePrice))        \n",
    "        print(\"  RMSE : %0.2f, %0.2f\" % (training_root_mean_squared_error, validation_root_mean_squared_error))\n",
    "        \n",
    "        # Add the loss metrics from this period to our list.\n",
    "        training_rmse.append(training_root_mean_squared_error)\n",
    "        validation_rmse.append(validation_root_mean_squared_error)\n",
    "    print(\"Model training finished.\")\n",
    "\n",
    "  \n",
    "    # Output a graph of loss metrics over periods.\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "    plt.tight_layout()\n",
    "    plt.plot(training_rmse, label=\"training\")\n",
    "    plt.plot(validation_rmse, label=\"validation\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return estimator\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_stupid_one_hot(data, feature, one_hot_map, feature_map):\n",
    "    for i in range(len(feature_map)):\n",
    "        data[feature_map[i]] = data[feature] == one_hot_map[i]\n",
    "    return data\n",
    "\n",
    "feature_map = ('ExterQual1', 'ExterQual2', 'ExterQual3', 'ExterQual4')\n",
    "one_hot_map = ('Gd', 'TA', 'Ex', 'Fa')\n",
    "\n",
    "data = my_stupid_one_hot(train_data, 'ExterQual', one_hot_map, feature_map)\n",
    "data = my_stupid_one_hot(test_data, 'ExterQual', one_hot_map, feature_map)\n",
    "# display.display(train_data.head(10))\n",
    "\n",
    "feature_map = ('BsmtQual1', 'BsmtQual2', 'BsmtQual3', 'BsmtQual4')\n",
    "one_hot_map = ('Gd', 'TA', 'Ex', 'Fa')\n",
    "\n",
    "data = my_stupid_one_hot(train_data, 'ExterQual', one_hot_map, feature_map)\n",
    "data = my_stupid_one_hot(test_data, 'ExterQual', one_hot_map, feature_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(series):\n",
    "    return (series - series.mean()) / series.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier and missing data\n",
    "outlier_data_set = pd.DataFrame({\n",
    "    '1stFlrSF':normalize(train_data['1stFlrSF'].apply(lambda x : min(x, 2500))),\n",
    "    'GrLivArea':normalize(train_data['GrLivArea'].apply(lambda x : min(x, 3000))),\n",
    "    'OverallQual':normalize(train_data['OverallQual']),\n",
    "    'FullBath':normalize(train_data['FullBath']),\n",
    "    'TotalBsmtSF':normalize(train_data['TotalBsmtSF'].apply(lambda x : min(x, 3000))),\n",
    "    'BsmtQual':train_data['BsmtQual'],\n",
    "    'SalePrice':np.log(train_data['SalePrice']),\n",
    "})\n",
    "\n",
    "estimator = train(\n",
    "    learning_rate = 0.01,\n",
    "    batch_size = 10,\n",
    "    steps = 100,\n",
    "    periods = 15,\n",
    "    train_example = missing_data_set,\n",
    "    mod_dir='./tensorboard/outlier2/train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final prediction\n",
    "def test_input(test_example):\n",
    "    test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "          x=test_example,\n",
    "          num_epochs=1, # only to predict\n",
    "          shuffle=False,\n",
    "    )\n",
    "    return test_input_fn\n",
    "\n",
    "test_simple_example = pd.DataFrame({\n",
    "    '1stFlrSF':normalize(test_data['1stFlrSF']),\n",
    "    'GrLivArea':normalize(test_data['GrLivArea']),\n",
    "    'OverallQual':normalize(test_data['OverallQual']),\n",
    "    'FullBath':normalize(test_data['FullBath']),\n",
    "    'TotalBsmtSF':normalize(test_data['TotalBsmtSF']),\n",
    "    'BsmtQual':test_data['BsmtQual'],\n",
    "})\n",
    "\n",
    "tmp = test_simple_example['TotalBsmtSF'].copy().dropna()\n",
    "tmp = test_simple_example['TotalBsmtSF'].sum() / len(test_simple_example['TotalBsmtSF'])\n",
    "test_simple_example['TotalBsmtSF'] = test_simple_example['TotalBsmtSF'].fillna(tmp)\n",
    "# print(test_simple_example['TotalBsmtSF'].isnull().sum())\n",
    "\n",
    "tmp = test_simple_example['GarageArea'].copy().dropna()\n",
    "tmp = test_simple_example['GarageArea'].sum() / len(test_simple_example['GarageArea'])\n",
    "test_simple_example['GarageArea'] = test_simple_example['GarageArea'].fillna(tmp)\n",
    "\n",
    "display.display(test_simple_example.info())\n",
    "final_input = test_input(test_simple_example)\n",
    "\n",
    "predictions = list(estimator.predict(input_fn=final_input))\n",
    "predicted_classes = [math.exp(float(prediction['predictions'][0])) for prediction in predictions]\n",
    "\n",
    "evaluation = test_data_copy[''].copy().to_frame()\n",
    "evaluation[\"SalePrice\"] = predicted_classes\n",
    "evaluation.to_csv(\"evaluation_submission.csv\", index=False)\n",
    "# evaluation[\"actual\"] = train_data.SalePrice\n",
    "display.display(evaluation.describe())\n",
    "display.display(evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
